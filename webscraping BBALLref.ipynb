{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os.path\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Lasso, LassoCV\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url2021 = 'https://www.basketball-reference.com/leagues/NBA_2021_per_game.html'\n",
    "url2020 = 'https://www.basketball-reference.com/leagues/NBA_2020_per_game.html'\n",
    "url2019 = 'https://www.basketball-reference.com/leagues/NBA_2019_per_game.html'\n",
    "url2018 = 'https://www.basketball-reference.com/leagues/NBA_2018_per_game.html'\n",
    "url2017 = 'https://www.basketball-reference.com/leagues/NBA_2017_per_game.html'\n",
    "url2016 = 'https://www.basketball-reference.com/leagues/NBA_2016_per_game.html'\n",
    "url2015 = 'https://www.basketball-reference.com/leagues/NBA_2015_per_game.html'\n",
    "url2014 = 'https://www.basketball-reference.com/leagues/NBA_2014_per_game.html'\n",
    "url2013 = 'https://www.basketball-reference.com/leagues/NBA_2013_per_game.html'\n",
    "url2012 = 'https://www.basketball-reference.com/leagues/NBA_2012_per_game.html'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(url2021)\n",
    "page = response.text\n",
    "soup = BeautifulSoup(page, \"lxml\")\n",
    "\n",
    "#Assigning header row to column\n",
    "headers = [th.getText() for th in soup.findAll('tr', limit=2)[0].findAll('th')]\n",
    "headers = headers[1:]\n",
    "#Web scrape text from table rows excluding header\n",
    "rows = soup.find_all('tr')[1:]\n",
    "player_stats = [[td.getText() for td in rows[i].find_all('td')]\n",
    "            for i in range(len(rows))]\n",
    "#Adding 2021 to df\n",
    "statstotal = pd.DataFrame(player_stats, columns = headers)\n",
    "statstotal['YEAR'] = 2021\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_list = [url2020, url2019, url2018, url2017, url2016, url2015, url2014, url2013, url2012]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, i in enumerate(url_list):\n",
    "    response = requests.get(i)\n",
    "    page = response.text\n",
    "    soup = BeautifulSoup(page, \"lxml\")\n",
    "    rows = soup.find_all('tr')[1:]\n",
    "    player_stats2 = [[td.getText() for td in rows[r].find_all('td')] for r in range(len(rows))]\n",
    "    stats = pd.DataFrame(player_stats2, columns = headers)\n",
    "    stats['YEAR'] = 2021-(index+1)\n",
    "    statstotal = statstotal.append(stats, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove duplicate rows for players who were traded (keep only TOT)\n",
    "statsclean = statstotal.drop_duplicates(subset = ['Player', 'YEAR'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "\n",
    "#Replace accented characters with normalized alphabet\n",
    "def remove_accents(input_str):\n",
    "    nfkd_form = unicodedata.normalize('NFKD', input_str)\n",
    "    return u\"\".join([c for c in nfkd_form if not unicodedata.combining(c)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-6ba7d2e3ef18>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  statsclean['Player'] = statsclean['Player'].astype('string')\n"
     ]
    }
   ],
   "source": [
    "statsclean['Player'] = statsclean['Player'].astype('string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "statsclean = statsclean.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "statsclean['Player'] = statsclean['Player'].apply(remove_accents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "statsclean.to_csv('bballref.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
